[{"content":"For data analysts and scientists (and other tech-job seekers), there are numerous online resources, communities, and platforms that can help with learning, networking, and staying updated with the latest trends and technologies.\nBut there are so many(!) and it might be overwhelming, so here are some key resources that I‚Äôd personally recommend to get you started:\nOnline Communities Kaggle Learn \u0026amp; Competitions - The best place to start is probably with one of Kaggle Learn tutorials, sign up with your email and then they will guide you through a practice competition. Otherwise, search for interesting datasets and publish your own notebooks, which you can then discuss with others, ask questions and learn from the community. For example try their Intro to Machine Learning mini-course. Stack Overflow - The world‚Äôs biggest community of software developers, a go-to for asking programming questions and finding solutions. You can also learn by helping others out, and making the community better by becoming a moderator. How to start? Have a look through the FAQs with some beginner guides and tips on asking questions. You might also want to checkout Cross Validated their sister website focusing on more techincal questions related to statistics, machine learning and data analysis. Learning Platforms Coursera - Offers courses and specializations in data science and machine learning from top universities and companies (specifically ML specialisation by Andrew Ng)\nedX - Provides data science courses from institutions like MIT, Harvard, and Microsoft. (like this Introduction to Data science)\nBlogs and Websites W3Schools - One of the most accessible and easy-to-follow tutorial blogs on Python, Data Science, PostgreSQL and more! It won\u0026rsquo;t go into great depth, but provides you with all the fundamentals you\u0026rsquo;ll need to get started on a topic.\nAnalytics Vidhya - Provides articles, hackathons, and a community forum for data science professionals. Check-out their guides, for a nice holitic overview of a topic, like this one on linear regression going from all the theory aspects to Python implementations.\nMachine Learning Mastery - Provides very high quality learning content, like this guide on Docker for beginners often going in a little deeper than some other sites, but still accessible.\nDataCamp - contains many useful walkthroughs and articles on their blog and they even offer a Data Science certification which would be a nice addition for your CV!\nStats LibreTexts - Free and open-source learning resource for statistics! Their introduction to statistics is perfect textbook for beginners who need to remember the difference between a standard deviation and a variance.\nNetworking and Events Meetup - Although not quite was it used to be, on Meetup you can find local and online tech meetups and events, like this Python meetup great for learning and networking! Tech conferences and festivals - Big cities often host interesting conferences and festivals, some free, some paid. For example, checkout the Green-tech festival coming to Berlin in 2025, or the Open Science Conference. More often than not, you\u0026rsquo;ll be at least be able to attend online for free! News and Updates Newsletters -Stay up to date with news and trends by following a weekly like this one by Open Data Science or Data Talks Club\nMIT Technology Review - The MIT Technology review site gives a nice curated overview of technology news often with a critical perspective.\nThese resources can help you stay informed, enhance your skills, and connect with other professionals in the field of data science and analytics.\nAny more resources you\u0026rsquo;d like to add to the list? Add your comments below\n","date":"2024-07-25T00:00:00Z","image":"https://wmbm.github.io/p/resources-for-learning-data-science/Collaborate_hu44590a5b89d1534896fc69167d4ce5ef_80700_120x120_fill_q75_box_smart1.jpg","permalink":"https://wmbm.github.io/p/resources-for-learning-data-science/","title":"Resources for learning data science"},{"content":" TLDR: Petitions have been around for hundreds of years, used by the powerful and the poor alike to advocate for change. In the 21st century, government petitions are still popular, and governments proactively collect and store data relating to signature counts and petition outcomes. However, the accessibility and usage of these datasets are non-optimal. Therefore, I developed a web scraper to gather and publish an open dataset of all UK government petitions available here. Future work will discover trends in this dataset, and scrutinise the effectiveness of this form of participatory democracy.\nWe often see petitions on our social media platforms demanding our governments do all sorts of things like ‚Äúmake Fridays a national pyjama day‚Äù or ‚ÄúDeclare ice cream an essential service‚Äù, but do they change anything?\nFor context, let\u0026rsquo;s first look into how petitioning came about in the first place\u0026hellip;\nA brief history of petitioning This bottom-up approach to direct democracy has a rich and fascinating history. The right to petition was written into the Magna Carta back in 1215, a foundational document in the history of European democracy, which established a Commission [1] that:\n\u0026ldquo;at every Parliament to hear by petition delivered to them, the Complaints of all those that will complain them of such Delays or Grievances done to them\u0026rdquo;\nSo, listen to the people! Well, at the time, it was more like listening to the church, rich landowners, and nobility. However, this precedent of petitioning paved the way for its inclusion in the 1689 UK Bill of Rights, which set out other basic civil rights such as free elections and freedom of speech for all subjects.\nPetitioning was also widespread in 18th-Century North America [2], inspired by the UK Bill of Rights. Emerging colonial assemblies, keen to resolve local disputes, encouraged petitions to validate their control and keep the colonisers from infighting. This was a time before the internet, and ruling powers needed the information to govern effectively. In this sense, petitioning was historically seen as an instrument of the elite and the state rather than a tool for the people.\nIn 1775, tensions between the North American colonies and Great Britain peaked, when the Olive Branch Petition [3] which was not even read by King George III, led to the American Revolutionary War and the eventual Declaration of Independence. So, indirectly, without petitions, there would be no USA!\nAfter the war, petitioning continued to be an important bureaucratic tool, and it was enshrined in the United States Bill of Rights in 1791. In some cases \u0026ndash; women, criminals, indigenous peoples, and even slaves \u0026ndash; voiced their grievances through petitions. However, as a backlog of petitions grew, a sense of unequal hearing developed and the influence of petitions was put to question, particularly during the rise of the abolition movement, which eventually resulted in a controversial ban on anti-slavery petitions [4] by the House of Representatives:\nNo petitions of resolutions \u0026ldquo;praying the abolition of slavery\u0026hellip; shall be received by this House, or entertained in any way whatever\u0026rdquo;\nDespite such barriers, abolitionist petitions provided a platform to articulate their anti-slavery arguments and mobilize public sentiment. Over time, the accumulation of their petitions contributed to legislative debates and ultimately culminated in the abolition of slavery in 1865.\nToday, the right to petition remains a continued aspect of democratic societies around the world. In the digital age, online petitions have amplified this practice, allowing for wider participation and awareness. The historical evolution of petitioning highlights its enduring importance as a tool for advocacy and change, reminding us of the possibilities that collective voices can have to shape society and influence governance.\nIntroduction Back to now, what happens to these petitions to the UK parliament? And which ones actually lead to concrete change?\nWell I wanted to find out, and thankfully under an Open Government Licence [5] the UK government publishes records of all petitions submitted and processed by the Petitions Committee [6]. So I went to the UK government petition website [7] to access the freely available data. However, as I came to find out, the tricky part is that ‚Äúopen-data‚Äù often translates to ‚Äúdata behind multiple little hurdles‚Äù.\n‚Äúopen-data‚Äù often translates to ‚Äúdata behind multiple little hurdles‚Äù\nFurthermore, there was no analysis provided; which I found curious. Which led me to ask: if the objective of this committee was truly noble, wouldn‚Äôt you expect they do their utmost to utilize and communicate the insights and findings from their own data? With millions of signatures submitted over the past decade, at the very least, this dataset is an invaluable barometer for public opinion.\nThe problem The website directory of ‚Äúall petitions‚Äù contains hundreds of pages, each with individual CSV or JSON files (a standard type of data file format). No-one has the time to click through all these, download and process them individually. How can we tame them?\nWell firstly better standards. And rather unfortunately for post-Brexit UK, from April 2024, the Interoperable Europe Act [8] will help towards this in all European member state governmental data portals - encouraging better standardisation and ensuring interoperability, a process which the UK will be left out of.\nCertainly, the current design of the UK petition data portal may have saved the developers time when building it (e.g. alleviate potential server load issues), however, the inability to allow full-batch downloads remains cumbersome and, I would argue, poses a significant obstacle to open-data portals and government transparency initiatives more generally - by creating huge friction in the access and acquisition of the data.\nOn top of this, petitions submitted under previous Governments are tucked away in an ‚Äúarchived‚Äù section at the bottom of the page, again with multiple sub-links and no batch downloads possible.\nWhile some of the smaller UK political parties acknowledge the failures of Brexit, talk of the UK returning to the EU single market, and re-adopting EU law, until then, we must either pray for a progressive \u0026amp; tech-minded UK government or get hacking!\nThe solution Luckily, that‚Äôs where the power of web-scraping comes in üí™ We can write scripts to automate this task. By creating a web scraper in Python (and the Selenium library) [9], we can guide a bot to automatically turn through each webpage and download the individual data files from each of the seperate sub-directories.\nAbove you can see the scraper in action, running through all the pages, and downloading the files faster than we ever could, ending up with around ~2000 files! It\u0026rsquo;s worth noting, that the only problem with these tools is that we must build a custom script for every unique website, each having their own unique map around their website. However, now that we have one for the petitions website, whenever we want to update our database with newly published petitions, we can just re-run our web scraper.\nAfter each of the files were downloaded, some cleaning and tidying was necessary, after which we could combine all the petition data into ONE SINGLE SOURCE!\nAnd you can access the full dataset here\nSo now we‚Äôve got the data, we can finally begin with the analysis (to be continued\u0026hellip;)\nUpcoming analysis The overall research questions will include:\nOf those petitions debated in parliament, how many led to new government initiatives? Which petition topics are most requested? What are the main reasons petitions to get rejected? How many voices (i.e. petition signatures) were listened to and how many went unheard? How has the number of petitions and signatures changed over time Tune in for Part 2, where I\u0026rsquo;ll be diving into some insights uncovered from this dataset.\nWant to contribute to this project? Feel free to start your own code space on Kaggle\nSomething you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below! Or message me on LinkedIn\nSources Statutes of the Realm, Edward III, 1312 A Short History of the Right To Petition Government for the Redress of Grievances, S. Higgson, Yale Law Journal, 1986 Olive Branch Petition Wikipedia Page Gag rule which banned anti-slavery petitions Open Government Licence Petitions Committee website UK government petition website Interoperable Europe Act, European Union, 2024 Selenium Python web scraper library ","date":"2024-07-10T00:00:00Z","image":"https://wmbm.github.io/p/do-government-petitions-actually-make-an-difference/ukpetitions_hufb844cd0cb36a43efcaf1a5cd244d5c7_72394_120x120_fill_q75_box_smart1.jpg","permalink":"https://wmbm.github.io/p/do-government-petitions-actually-make-an-difference/","title":"Do government petitions actually make an difference?"},{"content":"So you want to move into the data field but are unsure where to focus your energy? So many different tools, roles, programming langauges and technologies - where to start? Well\u0026hellip; look no further!\nIn this exploratory data analysis (EDA), we\u0026rsquo;ll explore data-related tech roles posted on LinkedIn to investigate which tools, activites and degrees are expected in these roles, and what is most in demand, to help you align yourself in your job-search. Let\u0026rsquo;s get into it!\nAnalysis tools So what is the difference between the tools you will be using in each job?\nData analyst roles typically use more high-level tools \u0026amp; software (often without any programming!) like Tableau and Excel. Although it can be seen that SQL is often expected across all data job roles. Python is a data scientists bread-and-butter, whilst Java and Scala are exclusively reserved for the Data Engineer.\nData-driven decision 1: Whichever role you decide upon, learning SQL is always going to be helpful! To deal with data you need to deal with databases, and to deal with databases you need SQL \u0026#x1f60c; Note: We excluded other tools and progrmaming languages because they were not referenced in the dataset.\nDaily activities How do the everyday activties of the roles differ?\nIt can be seen that a data analyst spends their time developing dashboards, reports and visualisations towards making analyses and insights. A data engineer is more focused towards developing data pipelines and infrastructure, including ETL and data warehousing. On the other hand, data scientists work to train machine leaning models, test models, conduct feature engineering and derive insights.\nData-driven decision 2: If you\u0026rsquo;re not so comfortable programming, going for a data analyst role might be more suitable. \u0026#x2728; University degrees Which university degrees are most in demand for these positions?\nData analysts typically come from statistics, finance or economics background (also business but this was excluded from the study). Data scientists tend to get a bit deeper into algorithms, and lower level programming, and therefore there is a need for a mathematics, physics or statistics background. A data engineer builds data software and architectures hence a high demand for a computer science background.\nKeep in mind, a job advert is just a guess from the hiring managers towards what their ideal person might look like, so even if you don\u0026rsquo;t come from this academic background, don\u0026rsquo;t be deterred! \u0026#x1f4aa; \u0026ldquo;If you meet all the job requirements, you\u0026rsquo;re overqualified\u0026rdquo;\nData-driven decision 3: Build on the experience you have already, and choose a degree path which matches your individual goals \u0026#x1f477; In closing Remember that the field of data analysis is constantly evolving, so staying updated with the latest tools, techniques, and technologies is crucial. Engage in continuous learning through online courses, building mini-projects, attending workshops and conferences, reading industry blogs and research papers, and participating in online communities like Stack Overflow, Kaggle or Reddit\u0026rsquo;s data science forums.\nAnd follow your interests like a devoted disciple! If you like sports, go into sport-analytics! If you\u0026rsquo;re passionate about the stock-market, get into fin-tech! If you\u0026rsquo;re interested in human rights, get into gov-tech! There\u0026rsquo;s a sub-category of almost every field in the data world, so get curious, and get building! That\u0026rsquo;s the real fuel to mastering any of these skills.\nFinally, the basics skills in the data field should not be overlooked. Mathematical fundamentals (like the differences between discrete and continous data), critical thinking (like how to formulate research questions) and communication (like reporting nuances in your results) are critical. The must-have tools typically needed are SQL + an analysis tool (like Python), so make sure you\u0026rsquo;re comfortable speaking in these languages.\nHopefully this overview gives you more confidence in your data job journey and helps shines some light on the topic!\nSomething you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below! Or message me on LinkedIn!\n","date":"2024-05-03T00:00:00Z","image":"https://wmbm.github.io/p/what-sets-apart-the-different-data-roles/banner_data_vs_final_hud6c4d722f5a13f10fab2b08b9ff4e2e6_34519_120x120_fill_box_smart1_3.png","permalink":"https://wmbm.github.io/p/what-sets-apart-the-different-data-roles/","title":"What sets apart the different data-roles?"},{"content":"So you want to move into the data field but are unsure where to focus your energy? So many different tools, roles, programming langauges and technologies - where to start? Well\u0026hellip; look no further!\nTLDR: If you want to be competing for Berlin data jobs in 2024, learn Python, SQL and AWS (also consider one Apache tool, like Spark or Airflow)\nIn this blogpost, I will explore some of the results from a descriptive analytics mini-project of +400 job ads from the Berlin tech market in March 2024.\nProgramming languages Firstly let\u0026rsquo;s investigate the most popular programming langauges in data jobs in Berlin.\nIt\u0026rsquo;s pretty clear that Python and SQL are the most in demand skills, with over a third of all data jobs asking for these skills respectively. The gender-diverse Kings and Queens of data analysis reign supreme! Now this may not be a huge surprise, but what is also interesting to note is the runners up:\nJava is commonly used for processing and analyzing large amounts of data efficiently. Scala excels at handling big data problems, favored by Apache Spark and compatible with Java.. R focuses on statistical analysis, with a large collection of packages for data analysis, visualization, and machine learning. C++ is a powerful programming language known for its efficiency, making it ideal for tasks requiring intense processing, like high-frequency trading or complex simulations. Open-source alert!: Notice how the only two \u0026ldquo;closed-source\u0026rdquo; languages are Matlab and SAS (and those you need to pay to use).\nLet\u0026rsquo;s move onto data analysis tools\u0026hellip;\nAnalysis tools Analysis tools are softwares which make engineers and analysts lives easier as part of their everyday workflow, including things like data visualisation, big data handling, scheduling and more\u0026hellip;\nHere most people will know Tableau and Excel but what about the other tools?\nSpark is an Apache tool that can handle and analyze large amounts of data quickly.. Airflow is another Apache tool for setting up and keeping an eye on a series of tasks, such as data processing or machine learning steps Databricks is a platform for storing data and building AI applications (also made by the developers of Apache Spark). What\u0026rsquo;s the deal with all this \u0026ldquo;Apache\u0026rdquo; software? Well, it\u0026rsquo;s part of the Apache Software Foundation (ASF) a non-profit organization that supports and promotes open-source software projects.\nOpen-source alert again!: With all this free and open-source software (FOSS) around, it\u0026rsquo;s almost surprising that Tableau is still kicking around in the most demanded tools, even though it is propreitary and closed-source, costing around ‚Ç¨500-‚Ç¨1000 per year. Do you think there will be a FOSS equivalent within the next 5 years?\nNext\u0026hellip; let\u0026rsquo;s check out the Python packages most in demand in 2024.\nPython packages What do all these Python packages do? Well Pytorch, Tensorflow and Keras are all deep learning and AI packages for complex machine learning problems. Pandas is your everyday data handling tool, scikitlearn your basic ML tool and matplotlib is used for visualisations. Basically, a comprehensive toolkit for building data analytics and machine learning tools!\nCloud technologies Last but not least, (turns on smoke machine) \u0026hellip; THE CLOUD \u0026hellip; (turns off smoke machine). Basically, \u0026ldquo;the cloud\u0026rdquo; is a shed somewhere with hundreds of computers which you pay someone to process or store your terrabytes of data instead of doing it on your struggling laptop. These days it\u0026rsquo;s a common expectation for data scientists and engineers to be experienced with cloud technologies for storage and/or processing purposes.\nLooking at the data tech jobs, a whopping 40% of job ads mentioned \u0026ldquo;cloud\u0026rdquo; with the most popular cloud service provider being AWS (Amazon Web Services), followed by Azure, the Microsoft equivalent.\nIn closing Finally, of course you have to remain critical and consider your own path, but hopefully this overview gives you more confidence in your data job journey.\nSomething you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below!\nCheckout the full analysis here\n","date":"2024-03-11T00:00:00Z","image":"https://wmbm.github.io/p/what-programming-languages-and-data-analysis-tools-to-learn-in-2024/banner_hub0a8d71bb0a30bdb829f0c8014bd2b7e_14914_120x120_fill_box_smart1_3.png","permalink":"https://wmbm.github.io/p/what-programming-languages-and-data-analysis-tools-to-learn-in-2024/","title":"What programming languages and data analysis tools to learn in 2024"},{"content":"This video lecture was part of the Post-graduate Certificate I completed in 2023, focusing on digital pedagogies in practice. Part of this involved critical evaluating digital tools for collabaorative learning. Here we looked at diagrams.net, a open-source, cloud-based diagramming software. If you\u0026rsquo;re an educator or facilitator this tool would certainly be of interest to you!\nHere\u0026rsquo;s the site if you want to try it out yourself.\nPart 1 Part 2 Something you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below!\n","date":"2023-09-07T00:00:00Z","image":"https://wmbm.github.io/p/critical-use-of-digital-tools-pgcert/critical_digital_peda_huee7c0d7a28182ba8e79561f76205ad55_2810031_120x120_fill_box_smart1_3.png","permalink":"https://wmbm.github.io/p/critical-use-of-digital-tools-pgcert/","title":"Critical use of digital tools (PGCert)"},{"content":"Over the past 50 years the CEO wage gap has dramatically increased.\nIn this mini-project, I wanted to created some visualisations to communicate this difference impactfully.\nSomething you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below!\nCheckout the full code here\n","date":"2023-08-24T00:00:00Z","image":"https://wmbm.github.io/p/ceo-wage-gap-in-the-top-3000-us-companies/CEO_wage_gap2_hu13805b3217ff4716e9bcbeb07a9f1941_101475_120x120_fill_box_smart1_3.png","permalink":"https://wmbm.github.io/p/ceo-wage-gap-in-the-top-3000-us-companies/","title":"CEO wage gap in the top 3000 US companies"},{"content":"Dataset: NBA players between 1990-2022\nProblem: Find how the game has changed over the eras\nTo explore the code on my Kaggle site\nSomething you\u0026rsquo;d like to add? If you have any questions or comments, feel free to add your thoughts below!\n","date":"2023-01-02T00:00:00Z","image":"https://wmbm.github.io/p/nba-players/nba2_hu7a7193f3eb6cbc11c98e31259f7fbdc7_104543_120x120_fill_box_smart1_3.png","permalink":"https://wmbm.github.io/p/nba-players/","title":"NBA Players"}]